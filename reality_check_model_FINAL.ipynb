{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aquamarine-28/Reality-Check/blob/updated_model_Nmesoma/reality_check_model_FINAL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files # Upload your API key from kaggle here\n",
        "files.upload()"
      ],
      "metadata": {
        "id": "tHSllgDSxaHg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir ~/.kaggle # Makes the directory for Kaggle and the dataset (so you dont have to download it)\n",
        "!cp kaggle.json ~/.kaggle\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "K4CgpGQYBWU0"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oqt7Yfi5aQuM",
        "outputId": "de3edfbb-a8a1-4b33-fe7e-196f3d6813c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "source": [
        "! kaggle datasets download manjilkarki/deepfake-and-real-images"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading deepfake-and-real-images.zip to /content\n",
            "100% 1.68G/1.68G [00:17<00:00, 102MB/s] \n",
            "100% 1.68G/1.68G [00:17<00:00, 102MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# (Comment this out when it has already been run, no need to run again)\n",
        "\n",
        "!pip install ultralytics\n",
        "!pip install datature --upgrade\n",
        "!unzip /content/deepfake-and-real-images.zip -d /content\n",
        "\n",
        "\n",
        "import os\n",
        "import tensorflow as tk\n",
        "from keras import layers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, BatchNormalization, Dropout\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "import cv2\n",
        "import PIL\n",
        "import ultralytics\n",
        "from ultralytics import YOLO\n",
        "\n",
        "\n",
        "ultralytics.checks()\n",
        "\n",
        "train_dir = '/content/Dataset/Train'\n",
        "validation_dir = '/content/Dataset/Validation'\n",
        "test_dir = '/content/Dataset/Test'"
      ],
      "metadata": {
        "id": "-t5S4Bq-xcL-",
        "outputId": "b9da841c-3c0f-4e7d-bd00-6c11399d62e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.1.42 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CPU (Intel Xeon 2.20GHz)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 33.0/107.7 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract face ROI from an image using YOLO\n",
        "def extract_face(img_path):\n",
        "\n",
        "# Perform object detection\n",
        "    results = model(img_path)\n",
        "    boxes = results[0].boxes\n",
        "    img = cv2.imread(img_path)\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    roi = None\n",
        "\n",
        "    if len(boxes) > 0:\n",
        "        for i, box in enumerate(boxes):\n",
        "            top_left_x = int(box.xyxy.tolist()[0][0])\n",
        "            top_left_y = int(box.xyxy.tolist()[0][1])\n",
        "            bottom_right_x = int(box.xyxy.tolist()[0][2])\n",
        "            bottom_right_y = int(box.xyxy.tolist()[0][3])\n",
        "\n",
        "        # Crop face region\n",
        "            roi = img[top_left_y:bottom_right_y, top_left_x:bottom_right_x]\n",
        "        return roi\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "# Additional variables like clip_limit and grid_size are defined outside the function.\n",
        "clip_limit = 2.0\n",
        "grid_size = (8,8)\n",
        "\n",
        "# Define data augmentation and normalization\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest')\n",
        "\n",
        "# Use datagen.flow_from_directory() to load images from the directory\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size=(224,224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary',\n",
        "    classes=['Fake', 'Real']\n",
        ")\n",
        "validation_generator = datagen.flow_from_directory(\n",
        "    '/content/Dataset/Validation',\n",
        "    target_size=(224,224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary',\n",
        "    classes=['Fake', 'Real']\n",
        ")\n",
        "test_generator = datagen.flow_from_directory(\n",
        "    '/content/Dataset/Test',\n",
        "    target_size=(224,224),\n",
        "    batch_size=16,\n",
        "    class_mode='binary',\n",
        "    classes=['Fake', 'Real']\n",
        ")\n",
        "# Define the model\n",
        "model = Sequential()\n",
        "\n",
        "# Convolutional Layer 1\n",
        "model.add(Conv2D(64, (3,3),\n",
        "                 activation='relu',\n",
        "                 padding='same',\n",
        "                 input_shape=(224,224,3)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Convolutional Layer 2\n",
        "model.add(Conv2D(64, (3,3), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3,3), activation='relu',padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "# Full Connected Layer\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Display the model summary\n",
        "model.summary()\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9vgWyxr8znfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3434d306-c480-4f48-b30e-a91702f88d1e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 140002 images belonging to 2 classes.\n",
            "Found 39428 images belonging to 2 classes.\n",
            "Found 10905 images belonging to 2 classes.\n",
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 224, 224, 64)      256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 74, 74, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 74, 74, 64)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 74, 74, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 74, 74, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 74, 74, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 74, 74, 64)        256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPoolin  (None, 37, 37, 64)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 37, 37, 64)        0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 87616)             0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 1024)              89719808  \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 1024)              4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 1025      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 89801345 (342.56 MB)\n",
            "Trainable params: 89798913 (342.56 MB)\n",
            "Non-trainable params: 2432 (9.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_generator, epochs = 40, validation_data=validation_generator)"
      ],
      "metadata": {
        "id": "pLg-Bvf9QGcL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}